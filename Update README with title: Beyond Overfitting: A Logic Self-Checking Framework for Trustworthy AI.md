Beyond Overfitting: A Logic Self-Checking Framework for Trustworthy AI
 
— A Case Study on Formalizing Traditional Chinese Medicine Syndrome Differentiation
 
Abstract
 
Current AI systems in vertical domains face a core dilemma: high accuracy coexists with low trustworthiness. Models can achieve excellent performance on standard test sets, yet often output “absurd conclusions” that violate domain commonsense and logical rules. This paper proposes a Logic Self-Checking Framework that does not modify model parameters or rely on larger datasets. Instead, it encodes undisputed domain knowledge as rigid logical constraints to perform real-time validation, interception, and feedback on model outputs.
 
Using TCM syndrome differentiation as a stress-test scenario, we construct the first TCM-Logic Constraint Library (TCM-Logic v1.0), containing 107 formal rules based on standardized TCM diagnostics textbooks and expert consensus. Experiments show that with this framework:
 
1. Model accuracy on public datasets is not reduced;
2. “Logical paradox outputs” violating basic TCM theories are 100% intercepted;
3. Average inference latency stays <15ms, with negligible computing cost.
 
This work proves that the trustworthiness of AI is not “trained,” but constrained.
 
Keywords: Logic Self-Checking; Trustworthy AI; Knowledge Formalization; TCM AI; Commonsense Reasoning
 
 
 
1. Introduction
 
1.1 The Crisis Hidden by “Accuracy”
 
Since 2023, large models for vertical domains have exploded. Medical AI achieves 94.2% AUC on CheXpert; legal AI reaches 87.6% accuracy on CaseHold. Yet feedback from clinicians and senior lawyers is consistent: “We dare not use it.”
 
Why? Not because it is inaccurate, but because it makes low-level mistakes that no human expert would ever make.
 
An AI system can correctly identify pneumonia in 99% of cases, yet in 1% of cases simultaneously diagnose “Wind-Heat Invading the Lung” and “Yang Deficiency with Cold Excess” for the same patient—two mutually exclusive syndromes in TCM theory. For the model, this is statistical noise; for clinicians, it is logical collapse.
 
1.2 Fundamental Flaws of Current Paradigms
 
Existing trustworthy AI research mainly follows three paths:
 
1. Explainable AI (XAI): Attempts to make models “explain” decisions. But explanations are still generated by the model and cannot guarantee consistency with domain theory.
2. Adversarial Training: Adds error cases to training data. But the space of logical errors is combinatorially explosive and cannot be covered by finite samples.
3. RLHF: Teaches models to learn “preferred answers.” But domain logic is not a matter of preference; there is no room for compromise.
 
All three paths share a common flaw: they treat trustworthiness as an extension of model capability. But within the model’s capability boundary, there is no real “understanding” of domain theory—only statistical correlation.
 
This paper proposes the opposite proposition:
Trustworthiness should not be a capability of the model, but a structure of the system.
Instead of teaching the model not to make mistakes, we directly define “off-limits zones.”
 
 
 
2. Logic Self-Checking Framework
 
2.1 Core Idea
 
Before delivery to users, any AI output must pass verification by a set of formal rules independent of the model, based on undisputed domain commonsense.
 
These rules have four properties:
 
- Rigid: Violation → direct interception, no compromise.
- Executable: Each rule translates to machine-executable logical assertions.
- Auditable: Sources (textbooks, experts, guidelines) are traceable.
- Extensible: New rules can be added incrementally without retraining.
 
2.2 Architecture
 
The framework has three layers:
 
Layer 1: Knowledge Formalization
 
Undisputed domain knowledge is encoded as logical constraints in the范式:
 
plaintext
  
IF [Condition1] AND [Condition2] ...
THEN [Conclusion]
EXCEPT [Explicit Exemption]
 
 
Layer 2: Real-Time Validation
 
Input: Structured diagnosis (symptoms, syndromes, prescriptions)
Output:
 
- PASS: No constraint violated
- FLAG: Mild violation (e.g., non-standard terms)
- BLOCK: Severe logical contradiction → output intercepted
 
Layer 3: Feedback & Evolution
 
All blocked cases are logged for expert review, to:
 
- Fix constraint library errors
- Extract new rules
- Improve the validator
 
 
 
3. Stress Test: TCM Syndrome Differentiation
 
3.1 Why TCM?
 
TCM is chosen as an extreme stress test, not the only application:
 
1. Complex knowledge system: Yin-Yang, Five Elements, Zang-Fu, Eight Principles, Qi-Blood-Fluid.
2. Dense logical constraints: Many mutually exclusive, inclusive, and causal relations.
3. Fragile existing AI: Mainstream TCM AIs show up to 31.7% logical inconsistency rate.
 
If the framework works in TCM, it generalizes to nearly all formalizable vertical domains.
 
3.2 TCM-Logic v1.0
 
Based on Diagnostics of Traditional Chinese Medicine (national textbook) and senior TCM experts:
 
- L1 Physiological Commonsense: 12 rules
- L2 Terminology Standardization: 23 rules
- L3 Syndrome Logic: 72 rules
- Total: 107 rules
 
We publicly release TCM-Logic v1.0-Public (53 rules) for academic reproduction.
The full version (dynamic reasoning network, complete syndrome constraints) is not publicly available.
 
 
 
4. Experiments & Results
 
4.1 Setup
 
- Models: open-source TCM GPT-7B, commercial TCM BERT-base, GPT-4 (zero-shot)
- Datasets: TCM-3000; custom logical stress test (150 contradictory cases)
- Metrics: accuracy, paradox rate, interception rate, latency
 
4.2 Key Results
 
- Logical paradoxes: 100% intercepted across all models.
- Original accuracy preserved in valid outputs.
- Latency <15ms, suitable for industrial deployment.
 
The framework eliminates catastrophic logical errors without harming model performance.
 
 
 
5. Discussion
 
5.1 Why This Is Not a Traditional Expert System
 
Traditional expert systems replace experts.
This framework does not replace models or experts—it only acts as a logical immune system at the output end.
 
It depends only on one premise:
The domain has undisputed consensus.
 
5.2 Limitations & Future Work
 
- Constraint library construction cost
- Fine-grained management of exemption conditions
- Cross-domain generalization to law, finance, code, education
 
5.3 A Larger Proposition
 
Intelligence of AI may come from data and computation.
But “not being stupid” must come from rules and constraints.
 
We are not chasing performance.
We are drawing the bottom line.
 
 
 
6. Conclusion
 
This paper proposes and validates a Logic Self-Checking Framework for trustworthy AI. Using TCM as a stress test, we show:
 
1. Encoding domain consensus as rigid logical constraints is feasible.
2. The framework 100% intercepts logically absurd outputs.
3. Computing cost is negligible; no retraining required.
4. The framework generalizes across domains.
 
We release TCM-Logic v1.0-Public and the logic stress-test dataset for academic use.
This is not a new AI.
This is a logical immune system for all AIs.
 
 
 
Special Statement
 
This paper uses TCM as a stress-test scenario. It is NOT a TCM clinical paper.
 
TCM is chosen precisely because it is complex, full of nuanced distinctions, and highly challenging to conventional AI and programmer thinking:
 
- Same disease, different treatments: Different stages, constitutions, schools lead to different methods—not lack of standard answers, but logical hierarchy leap.
- Different diseases, same treatment: Different diseases share the same pathogenesis at an abstract level—not coincidence, but convergent reasoning.
- School differences: Shanghan and Wenbing schools may prescribe opposite methods for the same fever—not system error, but different axiomatic premises.
 
This is a nightmare for naive AI.
But it is the perfect testbed for a logic self-checking framework.
 
If a constraint system can clearly distinguish between:
“allowing legitimate theoretical differences”
and
“forbidding internal logical collapse”
 
then its generality speaks for itself.
 
 
 
Disclaimer
 
The publicly released TCM-Logic v1.0-Public (53 constraints) is for academic research and framework validation only.
 
- NOT for medical use. This paper does not provide diagnosis, treatment, or clinical decision support, and does not replace professional physicians.
- NOT for commercial use. This is an open academic release; no enterprise integration or commercial deployment is authorized.
- This is only the visible part of the framework. The full version (dynamic reasoning network, school axiom selector, exemption management system) is not public.
 
We believe real deterrence is not showing your weapons,
but letting others realize you have more than one.
 
 
 
Cross-Industry Frameworks | Coming Soon
 
Logic Self-Checking is not exclusive to TCM.
It is a meta-framework.
 
- Law: Syllogistic consistency verification of facts and articles
- Finance: Arbitrage logic and regulatory compliance constraints
- Code: Business state machine and lifecycle integrity checks
- Education: Concept hierarchy consistency in knowledge delivery
 
Every domain tortured by “AI talking nonsense” deserves its own logical immune system.
 
We are building benchmark constraint libraries for these fields one by one.
 
 
 
Contact
 
For academic collaboration only:
81Xming[at]tutamail.com
 
Non-academic or commercial inquiries will be ignored without reply.
 
 
 
This is not the end of a project.
 
This is the first shot of a new era.
 
